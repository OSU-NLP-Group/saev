<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>saev.data.writers - saev</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "saev.data.writers";
        var mkdocs_page_input_path = "api/data/writers.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> saev
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Users</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../users/guide/">Guide</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../../users/inference/">Inference</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Developers</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../../developers/contributing/">Contributing</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">API</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../../saev/">saev</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../colors/">saev.colors</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../saev.data/">saev.data</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../__main__/">saev.data.main</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../buffers/">saev.data.buffers</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../clip/">saev.data.clip</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../datasets/">saev.data.datasets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../dinov2/">saev.data.dinov2</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../dinov3/">saev.data.dinov3</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../fake_clip/">saev.data.fake_clip</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../indexed/">saev.data.indexed</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../models/">saev.data.models</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../ordered/">saev.data.ordered</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../shuffled/">saev.data.shuffled</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../siglip/">saev.data.siglip</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../transforms/">saev.data.transforms</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">saev.data.writers</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.Config">Config</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.cls_token">cls_token</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.d_vit">d_vit</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.data">data</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.device">device</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.dump_to">dump_to</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.log_to">log_to</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.max_patches_per_shard">max_patches_per_shard</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.n_hours">n_hours</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.n_patches_per_img">n_patches_per_img</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.n_workers">n_workers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.slurm_acct">slurm_acct</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.slurm_partition">slurm_partition</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.ssl">ssl</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.vit_batch_size">vit_batch_size</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.vit_ckpt">vit_ckpt</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.vit_family">vit_family</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Config.vit_layers">vit_layers</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.IndexLookup">IndexLookup</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.IndexLookup--parameters">Parameters</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.IndexLookup.map_global">map_global</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#saev.data.writers.IndexLookup.map_global--return">Return</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.IndexLookup.map_img">map_img</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#saev.data.writers.IndexLookup.map_img--return">Return</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.LabelsWriter">LabelsWriter</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.LabelsWriter.flush">flush</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.LabelsWriter.write_batch">write_batch</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.Metadata">Metadata</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.Metadata.n_imgs_per_shard">n_imgs_per_shard</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.Shard">Shard</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.ShardInfo">ShardInfo</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.ShardWriter">ShardWriter</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.ShardWriter.__enter__">__enter__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.ShardWriter.__exit__">__exit__</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#saev.data.writers.ShardWriter.write_batch">write_batch</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.get_acts_dir">get_acts_dir</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.get_dataloader">get_dataloader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.pixel_to_patch_labels">pixel_to_patch_labels</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#saev.data.writers.worker_fn">worker_fn</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../helpers/">saev.helpers</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../nn/saev.nn/">saev.nn</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../nn/modeling/">saev.nn.modeling</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../nn/objectives/">saev.nn.objectives</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../utils/saev.utils/">saev.utils</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../utils/scheduling/">saev.utils.scheduling</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../utils/statistics/">saev.utils.statistics</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../utils/wandb/">saev.utils.wandb</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../viz/">saev.viz</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">saev</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">API</li>
      <li class="breadcrumb-item active">saev.data.writers</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <div class="doc doc-object doc-module">



<h2 id="saev.data.writers" class="doc doc-heading">
            <code>saev.data.writers</code>


</h2>

    <div class="doc doc-contents first">










  <div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.Config" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">Config</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">datasets</span><span class="o">.</span><span class="n">Imagenet</span><span class="p">(),</span> <span class="n">dump_to</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;shards&#39;</span><span class="p">),</span> <span class="n">vit_family</span><span class="o">=</span><span class="s1">&#39;clip&#39;</span><span class="p">,</span> <span class="n">vit_ckpt</span><span class="o">=</span><span class="s1">&#39;ViT-L-14/openai&#39;</span><span class="p">,</span> <span class="n">vit_batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">n_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">d_vit</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">vit_layers</span><span class="o">=</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])(),</span> <span class="n">n_patches_per_img</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">cls_token</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pixel_agg</span><span class="o">=</span><span class="s1">&#39;majority&#39;</span><span class="p">,</span> <span class="n">max_patches_per_shard</span><span class="o">=</span><span class="mi">2400000</span><span class="p">,</span> <span class="n">ssl</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">n_hours</span><span class="o">=</span><span class="mf">24.0</span><span class="p">,</span> <span class="n">slurm_acct</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">slurm_partition</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">log_to</span><span class="o">=</span><span class="s1">&#39;./logs&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">


        <p>Configuration for calculating and saving ViT activations.</p>











  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.cls_token" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">cls_token</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether the model has a [CLS] token.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.d_vit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">d_vit</span> <span class="o">=</span> <span class="mi">1024</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Dimension of the ViT activations (depends on model).</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">data</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="p">(</span><span class="n">datasets</span><span class="o">.</span><span class="n">Imagenet</span><span class="p">))</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Which dataset to use.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.device" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Which device to use.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.dump_to" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">dump_to</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;shards&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Where to write shards.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.log_to" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">log_to</span> <span class="o">=</span> <span class="s1">&#39;./logs&#39;</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Where to log Slurm job stdout/stderr.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.max_patches_per_shard" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">max_patches_per_shard</span> <span class="o">=</span> <span class="mi">2400000</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Maximum number of activations per shard; 2.4M is approximately 10GB for 1024-dimensional 4-byte activations.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.n_hours" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">n_hours</span> <span class="o">=</span> <span class="mf">24.0</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Slurm job length.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.n_patches_per_img" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">n_patches_per_img</span> <span class="o">=</span> <span class="mi">256</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Number of ViT patches per image (depends on model).</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.n_workers" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">n_workers</span> <span class="o">=</span> <span class="mi">8</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Number of dataloader workers.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.slurm_acct" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">slurm_acct</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Slurm account string.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.slurm_partition" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">slurm_partition</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Slurm partition.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.ssl" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">ssl</span> <span class="o">=</span> <span class="kc">True</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Whether to use SSL.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.vit_batch_size" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">vit_batch_size</span> <span class="o">=</span> <span class="mi">1024</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Batch size for ViT inference.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.vit_ckpt" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">vit_ckpt</span> <span class="o">=</span> <span class="s1">&#39;ViT-L-14/openai&#39;</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Specific model checkpoint.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.vit_family" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">vit_family</span> <span class="o">=</span> <span class="s1">&#39;clip&#39;</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Which model family.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Config.vit_layers" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">vit_layers</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]))</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-class-attribute"><code>class-attribute</code></small>
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Which layers to save. By default, the second-to-last layer.</p>

    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.IndexLookup" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">IndexLookup</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">patches</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">


        <p>Index &lt;-&gt; shard helper.</p>
<p><code>map()</code>      – turn a global dataset index into precise physical offsets.
<code>length()</code>   – dataset size for a particular (patches, layer) view.</p>
<h5 id="saev.data.writers.IndexLookup--parameters">Parameters</h5>
<p>metadata : Metadata
    Pre-computed dataset statistics (images, patches, layers, shard size).
patches: 'cls' | 'image' | 'all'
layer: int | 'all'</p>








                  <details class="quote">
                    <summary>Source code in <code>src/saev/data/writers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Metadata</span><span class="p">,</span>
    <span class="n">patches</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;cls&quot;</span><span class="p">,</span> <span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">],</span>
    <span class="n">layer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">tp</span><span class="o">.</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;all&quot;</span><span class="p">],</span>
<span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span><span class="o">.</span><span class="n">cls_token</span> <span class="ow">and</span> <span class="n">patches</span> <span class="o">==</span> <span class="s2">&quot;cls&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot return [CLS] token if one isn&#39;t present.&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">metadata</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patches</span> <span class="o">=</span> <span class="n">patches</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">layer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metadata</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Layer </span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s2"> not in </span><span class="si">{</span><span class="n">metadata</span><span class="o">.</span><span class="n">layers</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layer_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">layer</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">layers</span><span class="p">)}</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.IndexLookup.map_global" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">map_global</span><span class="p">(</span><span class="n">i</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <h6 id="saev.data.writers.IndexLookup.map_global--return">Return</h6>
<p>(
    shard_i,
    index in shard (img_i_in_shard, layer_i, token_i)
)</p>


            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">map_global</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return</span>
<span class="sd">    -------</span>
<span class="sd">    (</span>
<span class="sd">        shard_i,</span>
<span class="sd">        index in shard (img_i_in_shard, layer_i, token_i)</span>
<span class="sd">    )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">=}</span><span class="s2"> out of range [0, </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="k">match</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">patches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">):</span>
        <span class="k">case</span> <span class="p">(</span><span class="s2">&quot;cls&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">):</span>
            <span class="c1"># For CLS token with all layers, i represents (img_idx * n_layers + layer_idx)</span>
            <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
            <span class="n">img_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">n_layers</span>
            <span class="n">layer_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">n_layers</span>
            <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span>
            <span class="c1"># CLS token is at position 0</span>
            <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="p">(</span><span class="n">img_i_in_shard</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">case</span> <span class="p">(</span><span class="s2">&quot;cls&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">()):</span>
            <span class="c1"># For CLS token with specific layer, i is the image index</span>
            <span class="n">img_i</span> <span class="o">=</span> <span class="n">i</span>
            <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span>
            <span class="c1"># CLS token is at position 0</span>
            <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="p">(</span><span class="n">img_i_in_shard</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_to_idx</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">case</span> <span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">()):</span>
            <span class="c1"># For image patches with specific layer, i is (img_idx * n_patches_per_img + patch_idx)</span>
            <span class="n">img_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span>
            <span class="n">token_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span>

            <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="p">(</span><span class="n">img_i_in_shard</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_to_idx</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">],</span> <span class="n">token_i</span><span class="p">)</span>
        <span class="k">case</span> <span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">):</span>
            <span class="c1"># For image patches with all layers</span>
            <span class="c1"># Total patches per image across all layers</span>
            <span class="n">total_patches_per_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">layers</span>
            <span class="p">)</span>

            <span class="c1"># Calculate which image and which patch within that image across all layers</span>
            <span class="n">img_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">total_patches_per_img</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">total_patches_per_img</span>

            <span class="c1"># Calculate which layer and which patch within that layer</span>
            <span class="n">layer_idx</span> <span class="o">=</span> <span class="n">remainder</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span>
            <span class="n">token_i</span> <span class="o">=</span> <span class="n">remainder</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span>

            <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="p">(</span><span class="n">img_i_in_shard</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">token_i</span><span class="p">)</span>
        <span class="k">case</span> <span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">()):</span>
            <span class="n">n_tokens_per_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span> <span class="o">+</span> <span class="p">(</span>
                <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">cls_token</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="p">)</span>
            <span class="n">img_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">n_tokens_per_img</span>
            <span class="n">token_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">n_tokens_per_img</span>
            <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="p">(</span><span class="n">img_i_in_shard</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_to_idx</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">],</span> <span class="n">token_i</span><span class="p">)</span>
        <span class="k">case</span> <span class="p">(</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">):</span>
            <span class="c1"># For all tokens (CLS + patches) with all layers</span>
            <span class="c1"># Calculate total tokens per image across all layers</span>
            <span class="n">n_tokens_per_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_patches_per_img</span> <span class="o">+</span> <span class="p">(</span>
                <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">cls_token</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="p">)</span>
            <span class="n">total_tokens_per_img</span> <span class="o">=</span> <span class="n">n_tokens_per_img</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>

            <span class="c1"># Calculate which image and which token within that image</span>
            <span class="n">img_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">total_tokens_per_img</span>
            <span class="n">remainder</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">total_tokens_per_img</span>

            <span class="c1"># Calculate which layer and which token within that layer</span>
            <span class="n">layer_idx</span> <span class="o">=</span> <span class="n">remainder</span> <span class="o">//</span> <span class="n">n_tokens_per_img</span>
            <span class="n">token_i</span> <span class="o">=</span> <span class="n">remainder</span> <span class="o">%</span> <span class="n">n_tokens_per_img</span>

            <span class="c1"># Map to physical location</span>
            <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="p">(</span><span class="n">img_i_in_shard</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">token_i</span><span class="p">)</span>

        <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
            <span class="n">tp</span><span class="o">.</span><span class="n">assert_never</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">patches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.IndexLookup.map_img" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">map_img</span><span class="p">(</span><span class="n">img_i</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <h6 id="saev.data.writers.IndexLookup.map_img--return">Return</h6>
<p>(shard_i, img_i_in_shard)</p>


            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">map_img</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return</span>
<span class="sd">    -------</span>
<span class="sd">    (shard_i, img_i_in_shard)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">img_i</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">img_i</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_imgs</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">img_i</span><span class="si">=}</span><span class="s2"> out of range [0, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_imgs</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1"># Calculate which shard contains this image</span>
    <span class="n">shard_i</span> <span class="o">=</span> <span class="n">img_i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_imgs_per_shard</span>
    <span class="n">img_i_in_shard</span> <span class="o">=</span> <span class="n">img_i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">n_imgs_per_shard</span>

    <span class="k">return</span> <span class="n">shard_i</span><span class="p">,</span> <span class="n">img_i_in_shard</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.LabelsWriter" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">LabelsWriter</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">


        <p>LabelsWriter handles writing patch-level segmentation labels to a single binary file.</p>








                  <details class="quote">
                    <summary>Source code in <code>src/saev/data/writers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">Config</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;labels-writer&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">get_acts_dir</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_patches_per_img</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">n_imgs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">has_written</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_idx</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Always create memory-mapped file for labels</span>
    <span class="c1"># If nothing is written, it will be deleted in flush()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="s2">&quot;labels.bin&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_path</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w+&quot;</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_imgs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Opened labels file &#39;</span><span class="si">%s</span><span class="s2">&#39;.&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.LabelsWriter.flush" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">flush</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Flush the memory-mapped file to disk if anything was written.</p>


            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">flush</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Flush the memory-mapped file to disk if anything was written.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_written</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Flushed labels to &#39;</span><span class="si">%s</span><span class="s2">&#39;.&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels_path</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.LabelsWriter.write_batch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">write_batch</span><span class="p">(</span><span class="n">batch_labels</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Write a batch of labels to the memory-mapped file.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>batch_labels</code></b>
                  (<code><span title="numpy.ndarray">ndarray</span> | <span title="torch.Tensor">Tensor</span></code>)
              –
              <div class="doc-md-description">
                <p>Array of shape (batch_size, n_patches_per_img) with uint8 dtype</p>
              </div>
            </li>
            <li>
              <b><code>start_idx</code></b>
                  (<code><span title="int">int</span></code>)
              –
              <div class="doc-md-description">
                <p>Starting index in the global labels array</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@beartype</span><span class="o">.</span><span class="n">beartype</span>
<span class="k">def</span><span class="w"> </span><span class="nf">write_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Write a batch of labels to the memory-mapped file.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_labels: Array of shape (batch_size, n_patches_per_img) with uint8 dtype</span>
<span class="sd">        start_idx: Starting index in the global labels array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Convert to numpy if needed</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_labels</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">batch_labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_labels</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs</span>
    <span class="k">assert</span> <span class="n">batch_labels</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">batch_labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">start_idx</span> <span class="p">:</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_labels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">current_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">has_written</span> <span class="o">=</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.Metadata" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">Metadata</span><span class="p">(</span><span class="n">vit_family</span><span class="p">,</span> <span class="n">vit_ckpt</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">n_patches_per_img</span><span class="p">,</span> <span class="n">cls_token</span><span class="p">,</span> <span class="n">d_vit</span><span class="p">,</span> <span class="n">n_imgs</span><span class="p">,</span> <span class="n">max_patches_per_shard</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pixel_agg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="s1">&#39;1.1&#39;</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">












  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="saev.data.writers.Metadata.n_imgs_per_shard" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">n_imgs_per_shard</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Calculate the number of images per shard based on the protocol.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
                  <code><span title="int">int</span></code>
              –
              <div class="doc-md-description">
                <p>Number of images that fit in a shard.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>
    </div>

</div>






  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.Shard" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">Shard</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">n_imgs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">


        <p>A single shard entry in shards.json, recording the filename and number of images.</p>











  <div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.ShardInfo" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">ShardInfo</span><span class="p">(</span><span class="n">shards</span><span class="o">=</span><span class="nb">list</span><span class="p">())</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">


        <p>A read-only container for shard metadata as recorded in shards.json.</p>











  <div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="saev.data.writers.ShardWriter" class="doc doc-heading">
              <code class="highlight language-python"><span class="n">ShardWriter</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">


        <p>ShardWriter is a stateful object that handles sharded activation writing to disk.</p>








                  <details class="quote">
                    <summary>Source code in <code>src/saev/data/writers.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">Config</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;shard-writer&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">get_acts_dir</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

    <span class="n">n_patches_per_img</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span>
    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">cls_token</span><span class="p">:</span>
        <span class="n">n_patches_per_img</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">max_patches_per_shard</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">vit_layers</span><span class="p">)</span> <span class="o">//</span> <span class="n">n_patches_per_img</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span><span class="p">,</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">vit_layers</span><span class="p">),</span>
        <span class="n">n_patches_per_img</span><span class="p">,</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">d_vit</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># builder for shard manifest</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shards</span><span class="p">:</span> <span class="n">ShardInfo</span> <span class="o">=</span> <span class="n">ShardInfo</span><span class="p">()</span>

    <span class="c1"># Always initialize labels writer (it handles non-seg datasets internally)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span> <span class="o">=</span> <span class="n">LabelsWriter</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">shard</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">acts</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">next_shard</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.ShardWriter.__enter__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__enter__</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Context manager entry.</p>


            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Context manager entry.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.ShardWriter.__exit__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__exit__</span><span class="p">(</span><span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Context manager exit - handle cleanup.</p>


            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Context manager exit - handle cleanup.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="c1"># Delete empty labels file if nothing was written</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span><span class="o">.</span><span class="n">has_written</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span><span class="o">.</span><span class="n">labels_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span><span class="o">.</span><span class="n">labels_path</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Removed empty labels file &#39;</span><span class="si">%s</span><span class="s2">&#39;.&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span><span class="o">.</span><span class="n">labels_path</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="saev.data.writers.ShardWriter.write_batch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">write_batch</span><span class="p">(</span><span class="n">activations</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">patch_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Write a batch of activations and optionally patch labels.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>activations</code></b>
                  (<code><span title="jaxtyping.Float">Float</span>[<span title="torch.Tensor">Tensor</span>, &#39;batch n_layers all_patches d_vit&#39;]</code>)
              –
              <div class="doc-md-description">
                <p>Batch of activations to write.</p>
              </div>
            </li>
            <li>
              <b><code>start_idx</code></b>
                  (<code><span title="int">int</span></code>)
              –
              <div class="doc-md-description">
                <p>Starting index for this batch.</p>
              </div>
            </li>
            <li>
              <b><code>patch_labels</code></b>
                  (<code><span title="jaxtyping.UInt8">UInt8</span>[<span title="torch.Tensor">Tensor</span>, &#39;batch n_patches&#39;] | None</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Optional patch labels for segmentation datasets.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">write_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">activations</span><span class="p">:</span> <span class="n">Float</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;batch n_layers all_patches d_vit&quot;</span><span class="p">],</span>
    <span class="n">start_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">patch_labels</span><span class="p">:</span> <span class="n">UInt8</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot;batch n_patches&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Write a batch of activations and optionally patch labels.</span>

<span class="sd">    Args:</span>
<span class="sd">        activations: Batch of activations to write.</span>
<span class="sd">        start_idx: Starting index for this batch.</span>
<span class="sd">        patch_labels: Optional patch labels for segmentation datasets.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span>
    <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>

    <span class="c1"># Write activations (handling sharding)</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">shard</span>

    <span class="k">if</span> <span class="n">end_idx</span> <span class="o">&gt;=</span> <span class="n">offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span><span class="p">:</span>
        <span class="c1"># We have run out of space in this mmap&#39;ed file. Let&#39;s fill it as much as we can.</span>
        <span class="n">n_fit</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span> <span class="o">-</span> <span class="n">start_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acts</span><span class="p">[</span><span class="n">start_idx</span> <span class="o">-</span> <span class="n">offset</span> <span class="p">:</span> <span class="n">start_idx</span> <span class="o">-</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">n_fit</span><span class="p">]</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span>
            <span class="p">:</span><span class="n">n_fit</span>
        <span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filled</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">-</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">n_fit</span>

        <span class="c1"># Write labels for the portion that fits</span>
        <span class="k">if</span> <span class="n">patch_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Convert to numpy uint8 if needed</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">labels_to_write</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">patch_labels</span><span class="p">[:</span><span class="n">n_fit</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">labels_to_write</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">[:</span><span class="n">n_fit</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">labels_to_write</span> <span class="o">=</span> <span class="n">patch_labels</span><span class="p">[:</span><span class="n">n_fit</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span><span class="o">.</span><span class="n">write_batch</span><span class="p">(</span><span class="n">labels_to_write</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">next_shard</span><span class="p">()</span>

        <span class="c1"># Recursively call write_batch for remaining data</span>
        <span class="k">if</span> <span class="n">n_fit</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">write_batch</span><span class="p">(</span>
                <span class="n">activations</span><span class="p">[</span><span class="n">n_fit</span><span class="p">:],</span>
                <span class="n">start_idx</span> <span class="o">+</span> <span class="n">n_fit</span><span class="p">,</span>
                <span class="n">patch_labels</span><span class="p">[</span><span class="n">n_fit</span><span class="p">:]</span> <span class="k">if</span> <span class="n">patch_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;0 &lt;= </span><span class="si">{</span><span class="n">start_idx</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2"> &lt;= </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">start_idx</span> <span class="o">-</span> <span class="n">offset</span> <span class="o">&lt;=</span> <span class="n">offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span><span class="p">,</span> <span class="n">msg</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;0 &lt;= </span><span class="si">{</span><span class="n">end_idx</span><span class="si">}</span><span class="s2"> - </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2"> &lt;= </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2"> + </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">offset</span> <span class="o">&lt;=</span> <span class="n">offset</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_imgs_per_shard</span><span class="p">,</span> <span class="n">msg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acts</span><span class="p">[</span><span class="n">start_idx</span> <span class="o">-</span> <span class="n">offset</span> <span class="p">:</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">offset</span><span class="p">]</span> <span class="o">=</span> <span class="n">activations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filled</span> <span class="o">=</span> <span class="n">end_idx</span> <span class="o">-</span> <span class="n">offset</span>

        <span class="c1"># Write labels if provided</span>
        <span class="k">if</span> <span class="n">patch_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Convert to numpy uint8 if needed</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">patch_labels</span> <span class="o">=</span> <span class="n">patch_labels</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="n">patch_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">labels_writer</span><span class="o">.</span><span class="n">write_batch</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="saev.data.writers.get_acts_dir" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_acts_dir</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Return the activations directory based on the relevant values of a config.
Also saves a metadata.json file to that directory for human reference.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>cfg</code></b>
                  (<code><a class="autorefs autorefs-internal" title="Config(data=datasets.Imagenet(), dump_to=os.path.join('.', 'shards'), vit_family='clip', vit_ckpt='ViT-L-14/openai', vit_batch_size=1024, n_workers=8, d_vit=1024, vit_layers=(lambda: [-2])(), n_patches_per_img=256, cls_token=True, pixel_agg='majority', max_patches_per_shard=2400000, ssl=True, device='cuda', n_hours=24.0, slurm_acct='', slurm_partition='', log_to='./logs')

  
      dataclass
   (saev.data.writers.Config)" href="#saev.data.writers.Config">Config</a></code>)
              –
              <div class="doc-md-description">
                <p>Config for experiment.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
                  <code><span title="str">str</span></code>
              –
              <div class="doc-md-description">
                <p>Directory to where activations should be dumped/loaded from.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@beartype</span><span class="o">.</span><span class="n">beartype</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_acts_dir</span><span class="p">(</span><span class="n">cfg</span><span class="p">:</span> <span class="n">Config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the activations directory based on the relevant values of a config.</span>
<span class="sd">    Also saves a metadata.json file to that directory for human reference.</span>

<span class="sd">    Args:</span>
<span class="sd">        cfg: Config for experiment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Directory to where activations should be dumped/loaded from.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="n">Metadata</span><span class="o">.</span><span class="n">from_cfg</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>

    <span class="n">acts_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">dump_to</span><span class="p">,</span> <span class="n">metadata</span><span class="o">.</span><span class="n">hash</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">acts_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">metadata</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">acts_dir</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">acts_dir</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="saev.data.writers.get_dataloader" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_dataloader</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">img_tr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seg_tr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_tr</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Get a dataloader for a default map-style dataset.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>cfg</code></b>
                  (<code><a class="autorefs autorefs-internal" title="Config(data=datasets.Imagenet(), dump_to=os.path.join('.', 'shards'), vit_family='clip', vit_ckpt='ViT-L-14/openai', vit_batch_size=1024, n_workers=8, d_vit=1024, vit_layers=(lambda: [-2])(), n_patches_per_img=256, cls_token=True, pixel_agg='majority', max_patches_per_shard=2400000, ssl=True, device='cuda', n_hours=24.0, slurm_acct='', slurm_partition='', log_to='./logs')

  
      dataclass
   (saev.data.writers.Config)" href="#saev.data.writers.Config">Config</a></code>)
              –
              <div class="doc-md-description">
                <p>Config.</p>
              </div>
            </li>
            <li>
              <b><code>img_tr</code></b>
                  (<code><span title="collections.abc.Callable">Callable</span> | None</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Image transform to be applied to each image.</p>
              </div>
            </li>
            <li>
              <b><code>seg_tr</code></b>
                  (<code><span title="collections.abc.Callable">Callable</span> | None</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Segmentation transform to be applied to masks.</p>
              </div>
            </li>
            <li>
              <b><code>sample_tr</code></b>
                  (<code><span title="collections.abc.Callable">Callable</span> | None</code>, default:
                      <code>None</code>
)
              –
              <div class="doc-md-description">
                <p>Transform to be applied to sample dicts.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
                  <code><span title="torch.utils.data.DataLoader">DataLoader</span></code>
              –
              <div class="doc-md-description">
                <p>A PyTorch Dataloader that yields dictionaries with <code>'image'</code> keys containing image batches, <code>'index'</code> keys containing original dataset indices and <code>'label'</code> keys containing label batches.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@beartype</span><span class="o">.</span><span class="n">beartype</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_dataloader</span><span class="p">(</span>
    <span class="n">cfg</span><span class="p">:</span> <span class="n">Config</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">img_tr</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seg_tr</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_tr</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get a dataloader for a default map-style dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        cfg: Config.</span>
<span class="sd">        img_tr: Image transform to be applied to each image.</span>
<span class="sd">        seg_tr: Segmentation transform to be applied to masks.</span>
<span class="sd">        sample_tr: Transform to be applied to sample dicts.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A PyTorch Dataloader that yields dictionaries with `&#39;image&#39;` keys containing image batches, `&#39;index&#39;` keys containing original dataset indices and `&#39;label&#39;` keys containing label batches.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span>
        <span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">img_transform</span><span class="o">=</span><span class="n">img_tr</span><span class="p">,</span> <span class="n">seg_transform</span><span class="o">=</span><span class="n">seg_tr</span><span class="p">,</span> <span class="n">sample_transform</span><span class="o">=</span><span class="n">sample_tr</span>
    <span class="p">)</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">vit_batch_size</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_workers</span><span class="p">,</span>
        <span class="n">persistent_workers</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">n_workers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">dataloader</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="saev.data.writers.pixel_to_patch_labels" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">pixel_to_patch_labels</span><span class="p">(</span><span class="n">seg</span><span class="p">,</span> <span class="n">n_patches</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">,</span> <span class="n">pixel_agg</span><span class="o">=</span><span class="s1">&#39;majority&#39;</span><span class="p">,</span> <span class="n">bg_label</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_classes</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Convert pixel-level segmentation to patch-level labels using vectorized operations.</p>


<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>seg</code></b>
                  (<code><span title="PIL.Image.Image">Image</span></code>)
              –
              <div class="doc-md-description">
                <p>Pixel-level segmentation mask as PIL Image</p>
              </div>
            </li>
            <li>
              <b><code>n_patches</code></b>
                  (<code><span title="int">int</span></code>)
              –
              <div class="doc-md-description">
                <p>Total number of patches expected</p>
              </div>
            </li>
            <li>
              <b><code>patch_size</code></b>
                  (<code><span title="int">int</span></code>)
              –
              <div class="doc-md-description">
                <p>Size of each patch in pixels</p>
              </div>
            </li>
            <li>
              <b><code>pixel_agg</code></b>
                  (<code><span title="typing.Literal">Literal</span>[&#39;majority&#39;, &#39;prefer-fg&#39;]</code>, default:
                      <code>&#39;majority&#39;</code>
)
              –
              <div class="doc-md-description">
                <p>How to aggregate pixel labels into patch labels</p>
              </div>
            </li>
            <li>
              <b><code>bg_label</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>0</code>
)
              –
              <div class="doc-md-description">
                <p>Background label index</p>
              </div>
            </li>
            <li>
              <b><code>max_classes</code></b>
                  (<code><span title="int">int</span></code>, default:
                      <code>256</code>
)
              –
              <div class="doc-md-description">
                <p>Maximum number of classes (for bincount)</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Returns:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
                  <code><span title="jaxtyping.UInt8">UInt8</span>[<span title="torch.Tensor">Tensor</span>, &#39; n_patches&#39;]</code>
              –
              <div class="doc-md-description">
                <p>Patch labels as uint8 tensor of shape (n_patches,)</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@jaxtyped</span><span class="p">(</span><span class="n">typechecker</span><span class="o">=</span><span class="n">beartype</span><span class="o">.</span><span class="n">beartype</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pixel_to_patch_labels</span><span class="p">(</span>
    <span class="n">seg</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">,</span>
    <span class="n">n_patches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pixel_agg</span><span class="p">:</span> <span class="n">tp</span><span class="o">.</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;majority&quot;</span><span class="p">,</span> <span class="s2">&quot;prefer-fg&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;majority&quot;</span><span class="p">,</span>
    <span class="n">bg_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">max_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">UInt8</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="s2">&quot; n_patches&quot;</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert pixel-level segmentation to patch-level labels using vectorized operations.</span>

<span class="sd">    Args:</span>
<span class="sd">        seg: Pixel-level segmentation mask as PIL Image</span>
<span class="sd">        n_patches: Total number of patches expected</span>
<span class="sd">        patch_size: Size of each patch in pixels</span>
<span class="sd">        pixel_agg: How to aggregate pixel labels into patch labels</span>
<span class="sd">        bg_label: Background label index</span>
<span class="sd">        max_classes: Maximum number of classes (for bincount)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Patch labels as uint8 tensor of shape (n_patches,)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Convert to torch tensor for vectorized operations</span>
    <span class="n">seg_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">seg</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">seg_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span>

    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">seg_tensor</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># Calculate patch grid dimensions</span>
    <span class="n">patch_grid_h</span> <span class="o">=</span> <span class="n">h</span> <span class="o">//</span> <span class="n">patch_size</span>
    <span class="n">patch_grid_w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">//</span> <span class="n">patch_size</span>
    <span class="k">assert</span> <span class="n">patch_grid_w</span> <span class="o">*</span> <span class="n">patch_grid_h</span> <span class="o">==</span> <span class="n">n_patches</span><span class="p">,</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Image size </span><span class="si">{</span><span class="n">w</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">h</span><span class="si">}</span><span class="s2"> with patch_size </span><span class="si">{</span><span class="n">patch_size</span><span class="si">}</span><span class="s2"> gives </span><span class="si">{</span><span class="n">patch_grid_w</span><span class="si">}</span><span class="s2">x</span><span class="si">{</span><span class="n">patch_grid_h</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">patch_grid_w</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">patch_grid_h</span><span class="si">}</span><span class="s2"> patches, expected </span><span class="si">{</span><span class="n">n_patches</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Reshape into patches using einops: (n_patches, patch_size * patch_size)</span>
    <span class="n">patches</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span>
        <span class="n">seg_tensor</span><span class="p">,</span>
        <span class="s2">&quot;(h p1) (w p2) -&gt; (h w) (p1 p2)&quot;</span><span class="p">,</span>
        <span class="n">p1</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
        <span class="n">p2</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
        <span class="n">h</span><span class="o">=</span><span class="n">patch_grid_h</span><span class="p">,</span>
        <span class="n">w</span><span class="o">=</span><span class="n">patch_grid_w</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Use vectorized bincount approach to get class counts for all patches at once</span>
    <span class="c1"># counts[i, c] = number of times class c appears in patch i</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_patches</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">patches</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_classes</span>
    <span class="n">flat</span> <span class="o">=</span> <span class="p">(</span><span class="n">patches</span> <span class="o">+</span> <span class="n">offsets</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">flat</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="n">n_patches</span> <span class="o">*</span> <span class="n">max_classes</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">n_patches</span><span class="p">,</span> <span class="n">max_classes</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">pixel_agg</span> <span class="o">==</span> <span class="s2">&quot;majority&quot;</span><span class="p">:</span>
        <span class="c1"># Take the most common label in each patch</span>
        <span class="n">patch_labels</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">pixel_agg</span> <span class="o">==</span> <span class="s2">&quot;prefer-fg&quot;</span><span class="p">:</span>
        <span class="c1"># Take the most common non-background label, or background if all background</span>
        <span class="n">nonbg</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">nonbg</span><span class="p">[:,</span> <span class="n">bg_label</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">has_nonbg</span> <span class="o">=</span> <span class="n">nonbg</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">nonbg_arg</span> <span class="o">=</span> <span class="n">nonbg</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">bg_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">nonbg_arg</span><span class="p">,</span> <span class="n">bg_label</span><span class="p">)</span>
        <span class="n">patch_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">has_nonbg</span><span class="p">,</span> <span class="n">nonbg_arg</span><span class="p">,</span> <span class="n">bg_tensor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tp</span><span class="o">.</span><span class="n">assert_never</span><span class="p">(</span><span class="n">pixel_agg</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">patch_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="saev.data.writers.worker_fn" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">worker_fn</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<table class="field-list">
  <colgroup>
    <col class="field-name" />
    <col class="field-body" />
  </colgroup>
  <tbody valign="top">
    <tr class="field">
      <th class="field-name">Parameters:</th>
      <td class="field-body">
        <ul class="first simple">
            <li>
              <b><code>cfg</code></b>
                  (<code><a class="autorefs autorefs-internal" title="Config(data=datasets.Imagenet(), dump_to=os.path.join('.', 'shards'), vit_family='clip', vit_ckpt='ViT-L-14/openai', vit_batch_size=1024, n_workers=8, d_vit=1024, vit_layers=(lambda: [-2])(), n_patches_per_img=256, cls_token=True, pixel_agg='majority', max_patches_per_shard=2400000, ssl=True, device='cuda', n_hours=24.0, slurm_acct='', slurm_partition='', log_to='./logs')

  
      dataclass
   (saev.data.writers.Config)" href="#saev.data.writers.Config">Config</a></code>)
              –
              <div class="doc-md-description">
                <p>Config for activations.</p>
              </div>
            </li>
        </ul>
      </td>
    </tr>
  </tbody>
</table>

            <details class="quote">
              <summary>Source code in <code>src/saev/data/writers.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@beartype</span><span class="o">.</span><span class="n">beartype</span>
<span class="k">def</span><span class="w"> </span><span class="nf">worker_fn</span><span class="p">(</span><span class="n">cfg</span><span class="p">:</span> <span class="n">Config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        cfg: Config for activations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">models</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="c1"># This enables tf32 on Ampere GPUs which is only 8% slower than</span>
        <span class="c1"># float16 and almost as accurate as float32</span>
        <span class="c1"># This was a default in pytorch until 1.12</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">matmul</span><span class="o">.</span><span class="n">allow_tf32</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">log_format</span> <span class="o">=</span> <span class="s2">&quot;[</span><span class="si">%(asctime)s</span><span class="s2">] [</span><span class="si">%(levelname)s</span><span class="s2">] [</span><span class="si">%(name)s</span><span class="s2">] </span><span class="si">%(message)s</span><span class="s2">&quot;</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">log_format</span><span class="p">)</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;worker_fn&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;No CUDA device available, using CPU.&quot;</span><span class="p">)</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="n">vit_cls</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">load_vit_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">vit_family</span><span class="p">)</span>
    <span class="n">vit_instance</span> <span class="o">=</span> <span class="n">vit_cls</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">vit_ckpt</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">vit</span> <span class="o">=</span> <span class="n">RecordedVisionTransformer</span><span class="p">(</span>
        <span class="n">vit_instance</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">cls_token</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">vit_layers</span>
    <span class="p">)</span>

    <span class="n">img_tr</span><span class="p">,</span> <span class="n">sample_tr</span> <span class="o">=</span> <span class="n">vit_cls</span><span class="o">.</span><span class="n">make_transforms</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">vit_ckpt</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">)</span>

    <span class="n">seg_tr</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">_is_segmentation_dataset</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="p">):</span>
        <span class="c1"># For segmentation datasets, create a transform that converts pixels to patches</span>
        <span class="c1"># Use make_resize with NEAREST interpolation for segmentation masks</span>
        <span class="n">seg_resize_tr</span> <span class="o">=</span> <span class="n">vit_cls</span><span class="o">.</span><span class="n">make_resize</span><span class="p">(</span>
            <span class="n">cfg</span><span class="o">.</span><span class="n">vit_ckpt</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">resample</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">NEAREST</span>
        <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">seg_to_patches</span><span class="p">(</span><span class="n">seg</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Transform that resizes segmentation and converts to patch labels.&quot;&quot;&quot;</span>

            <span class="c1"># Convert to patch labels</span>
            <span class="k">return</span> <span class="n">pixel_to_patch_labels</span><span class="p">(</span>
                <span class="n">seg_resize_tr</span><span class="p">(</span><span class="n">seg</span><span class="p">),</span>
                <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">,</span>
                <span class="n">patch_size</span><span class="o">=</span><span class="n">vit_instance</span><span class="o">.</span><span class="n">patch_size</span><span class="p">,</span>
                <span class="n">pixel_agg</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">pixel_agg</span><span class="p">,</span>
                <span class="n">bg_label</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">bg_label</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">seg_tr</span> <span class="o">=</span> <span class="n">seg_to_patches</span>

    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">img_tr</span><span class="o">=</span><span class="n">img_tr</span><span class="p">,</span> <span class="n">seg_tr</span><span class="o">=</span><span class="n">seg_tr</span><span class="p">,</span> <span class="n">sample_tr</span><span class="o">=</span><span class="n">sample_tr</span><span class="p">)</span>

    <span class="n">n_batches</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">n_imgs</span> <span class="o">/</span> <span class="n">cfg</span><span class="o">.</span><span class="n">vit_batch_size</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Dumping </span><span class="si">%d</span><span class="s2"> batches of </span><span class="si">%d</span><span class="s2"> examples.&quot;</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">vit_batch_size</span><span class="p">)</span>

    <span class="n">vit</span> <span class="o">=</span> <span class="n">vit</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># vit = torch.compile(vit)</span>

    <span class="c1"># Use context manager for proper cleanup</span>
    <span class="k">with</span> <span class="n">ShardWriter</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Calculate and write ViT activations.</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">helpers</span><span class="o">.</span><span class="n">progress</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_batches</span><span class="p">):</span>
                <span class="n">imgs</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">grid</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;grid&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">grid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">grid</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">out</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">vit</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">grid</span><span class="o">=</span><span class="n">grid</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">vit</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
                <span class="c1"># cache has shape [batch size, n layers, n patches + 1, d vit]</span>
                <span class="k">del</span> <span class="n">out</span>

                <span class="c1"># Write activations and labels (if present) in one call</span>
                <span class="n">patch_labels</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;patch_labels&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">patch_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Found patch_labels in batch: shape=</span><span class="si">{</span><span class="n">patch_labels</span><span class="o">.</span><span class="n">shape</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">hasattr</span><span class="p">(</span><span class="n">patch_labels</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;shape&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;unknown&#39;</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="c1"># Ensure correct shape</span>
                    <span class="k">assert</span> <span class="n">patch_labels</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cache</span><span class="p">),</span> <span class="n">cfg</span><span class="o">.</span><span class="n">n_patches_per_img</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No patch_labels in batch. Keys: </span><span class="si">{</span><span class="n">batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="n">writer</span><span class="o">.</span><span class="n">write_batch</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">patch_labels</span><span class="o">=</span><span class="n">patch_labels</span><span class="p">)</span>

                <span class="n">i</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cache</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../transforms/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../../helpers/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(false);
        });
    </script>

</body>
</html>
